{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üé≠ Emotion Recognition - Quick Start\n",
    "\n",
    "This notebook allows you to quickly set up and train the emotion recognition model on Google Colab."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Clone Repository"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clone the repository\n",
    "!git clone https://github.com/Wafflelover404/VC-emo-project.git\n",
    "%cd VC-emo-project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Install Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages\n",
    "!pip install -q torch torchvision scikit-learn matplotlib pandas pillow opencv-python streamlit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Download Dataset (FER2013)\n",
    "\n",
    "The project uses the FER2013 dataset. Download and prepare it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Option A: Download FER2013 from Kaggle (requires auth)\n",
    "# !pip install kaggle\n",
    "# !kaggle datasets download -d msambare/fer2013\n",
    "# !unzip -q fer2013.zip -d data/\n",
    "\n",
    "# Option B: Download from alternative source\n",
    "!wget -q https://www.dropbox.com/s/1w0j7pfr05eulc9/fer2013.tar.gz -O fer2013.tar.gz 2>/dev/null || echo \"Using alternative source...\"\n",
    "!tar -xzf fer2013.tar.gz 2>/dev/null && mv fer2013 data/ || echo \"Dataset folder already exists or download failed\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Prepare Dataset Structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create train/test folders if needed\n",
    "import os\n",
    "os.makedirs('train', exist_ok=True)\n",
    "os.makedirs('test', exist_ok=True)\n",
    "\n",
    "# Check if data exists\n",
    "if os.path.exists('data/fer2013'):\n",
    "    print(\"Dataset found at data/fer2013\")\n",
    "    print(os.listdir('data/fer2013')[:10])\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è Dataset not found. Please upload manually or use alternative method.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Training Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Training parameters (modify as needed)\n",
    "EPOCHS = 30\n",
    "IMG_SIZE = 224\n",
    "BATCH_SIZE = 32\n",
    "LR = 0.0003\n",
    "WEIGHT_DECAY = 0.01\n",
    "UNFREEZE = \"layer4\"\n",
    "\n",
    "# Set environment variables\n",
    "os.environ['EPOCHS'] = str(EPOCHS)\n",
    "os.environ['IMG_SIZE'] = str(IMG_SIZE)\n",
    "os.environ['BATCH_SIZE'] = str(BATCH_SIZE)\n",
    "os.environ['LR'] = str(LR)\n",
    "os.environ['WEIGHT_DECAY'] = str(WEIGHT_DECAY)\n",
    "os.environ['UNFREEZE'] = UNFREEZE\n",
    "\n",
    "print(f\"Training config:\")\n",
    "print(f\"  EPOCHS: {EPOCHS}\")\n",
    "print(f\"  IMG_SIZE: {IMG_SIZE}\")\n",
    "print(f\"  BATCH_SIZE: {BATCH_SIZE}\")\n",
    "print(f\"  LR: {LR}\")\n",
    "print(f\"  WEIGHT_DECAY: {WEIGHT_DECAY}\")\n",
    "print(f\"  UNFREEZE: {UNFREEZE}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Run Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run training script\n",
    "# Note: Make sure dataset is in train/ and test/ folders\n",
    "!python src/train_model.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Streamlit Demo (Optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run Streamlit app (requires ngrok or localtunnel for Colab)\n",
    "# !pip install streamlit ngrok\n",
    "# !ngrok authtoken YOUR_TOKEN  # Add your ngrok token\n",
    "# !streamlit run src/streamlit_app.py &"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
