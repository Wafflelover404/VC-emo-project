{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Wafflelover404/VC-emo-project/blob/main/quick_start.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UZ9tjpNEwlsn"
      },
      "source": [
        "# üé≠ Emotion Recognition - Quick Start\n",
        "\n",
        "This notebook allows you to quickly set up and train the emotion recognition model on Google Colab."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4qhkoV7swlsr"
      },
      "source": [
        "## 1. Clone Repository"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "dTo3CLk3wlsr",
        "outputId": "51c22674-088b-4751-cfaf-cd5d39d5acd7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'VC-emo-project'...\n",
            "remote: Enumerating objects: 34192, done.\u001b[K\n",
            "remote: Total 34192 (delta 0), reused 0 (delta 0), pack-reused 34192 (from 2)\u001b[K\n",
            "Receiving objects: 100% (34192/34192), 378.37 MiB | 10.03 MiB/s, done.\n",
            "Resolving deltas: 100% (28/28), done.\n",
            "Updating files: 100% (35979/35979), done.\n",
            "/content/VC-emo-project/VC-emo-project\n"
          ]
        }
      ],
      "source": [
        "# Clone the repository\n",
        "!git clone https://github.com/Wafflelover404/VC-emo-project.git\n",
        "%cd VC-emo-project"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VVqCU0DNwlss"
      },
      "source": [
        "## 2. Install Dependencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "xzcMy6BLwlss"
      },
      "outputs": [],
      "source": [
        "# Install required packages\n",
        "!pip install -q torch torchvision scikit-learn matplotlib pandas pillow opencv-python streamlit"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V4h9CrTewlss"
      },
      "source": [
        "## 3. Download Dataset (FER2013)\n",
        "\n",
        "The project uses the FER2013 dataset. Download and prepare it:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "8RMv7P35wlss",
        "outputId": "d0c91f4d-3014-43c5-f965-2cc1e72b6e25",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset folder already exists or download failed\n"
          ]
        }
      ],
      "source": [
        "# Option A: Download FER2013 from Kaggle (requires auth)\n",
        "# !pip install kaggle\n",
        "# !kaggle datasets download -d msambare/fer2013\n",
        "# !unzip -q fer2013.zip -d data/\n",
        "\n",
        "# Option B: Download from alternative source\n",
        "!wget -q https://www.dropbox.com/s/1w0j7pfr05eulc9/fer2013.tar.gz -O fer2013.tar.gz 2>/dev/null || echo \"Using alternative source...\"\n",
        "!tar -xzf fer2013.tar.gz 2>/dev/null && mv fer2013 data/ || echo \"Dataset folder already exists or download failed\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JBLs1sV9wlss"
      },
      "source": [
        "## 4. Prepare Dataset Structure"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "7l86qirlwlst",
        "outputId": "902ecf8b-99dd-4b1f-f46f-17c25ae70f00",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚ö†Ô∏è Dataset not found. Please upload manually or use alternative method.\n"
          ]
        }
      ],
      "source": [
        "# Create train/test folders if needed\n",
        "import os\n",
        "os.makedirs('train', exist_ok=True)\n",
        "os.makedirs('test', exist_ok=True)\n",
        "\n",
        "# Check if data exists\n",
        "if os.path.exists('data/fer2013'):\n",
        "    print(\"Dataset found at data/fer2013\")\n",
        "    print(os.listdir('data/fer2013')[:10])\n",
        "else:\n",
        "    print(\"‚ö†Ô∏è Dataset not found. Please upload manually or use alternative method.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VBf5y-EWwlst"
      },
      "source": [
        "## 5. Training Configuration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "QiV_4FbUwlst",
        "outputId": "65fe6133-c9a7-46d4-fade-abc662abb42d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training config:\n",
            "  EPOCHS: 30\n",
            "  IMG_SIZE: 224\n",
            "  BATCH_SIZE: 32\n",
            "  LR: 0.0003\n",
            "  WEIGHT_DECAY: 0.01\n",
            "  UNFREEZE: layer4\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "# Training parameters (modify as needed)\n",
        "EPOCHS = 30\n",
        "IMG_SIZE = 224\n",
        "BATCH_SIZE = 32\n",
        "LR = 0.0003\n",
        "WEIGHT_DECAY = 0.01\n",
        "UNFREEZE = \"layer4\"\n",
        "\n",
        "# Set environment variables\n",
        "os.environ['EPOCHS'] = str(EPOCHS)\n",
        "os.environ['IMG_SIZE'] = str(IMG_SIZE)\n",
        "os.environ['BATCH_SIZE'] = str(BATCH_SIZE)\n",
        "os.environ['LR'] = str(LR)\n",
        "os.environ['WEIGHT_DECAY'] = str(WEIGHT_DECAY)\n",
        "os.environ['UNFREEZE'] = UNFREEZE\n",
        "\n",
        "print(f\"Training config:\")\n",
        "print(f\"  EPOCHS: {EPOCHS}\")\n",
        "print(f\"  IMG_SIZE: {IMG_SIZE}\")\n",
        "print(f\"  BATCH_SIZE: {BATCH_SIZE}\")\n",
        "print(f\"  LR: {LR}\")\n",
        "print(f\"  WEIGHT_DECAY: {WEIGHT_DECAY}\")\n",
        "print(f\"  UNFREEZE: {UNFREEZE}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BPa-Oz_rwlst"
      },
      "source": [
        "## 6. Run Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5r2_K_AIwlst",
        "outputId": "e55d3098-0b00-49f1-a557-fea687590f82",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "[2026-02-14 10:47:42] Device: cuda:0\n",
            "[2026-02-14 10:47:42] FAST=0 IMG_SIZE=224 BATCH_SIZE=32 EPOCHS=30\n",
            "[2026-02-14 10:47:42] LR=0.0003 WEIGHT_DECAY=0.01 UNFREEZE=layer4\n",
            "[2026-02-14 10:47:42] Train samples: 28709  Test samples: 7178\n",
            "[2026-02-14 10:47:42] Train class distribution: angry=3995, disgust=436, fear=4097, happy=7215, neutral=4965, sad=4830, surprise=3171\n",
            "[2026-02-14 10:47:42] Epoch 1/30\n",
            "[2026-02-14 10:47:42] LR: 0.000150\n",
            "[2026-02-14 10:47:52]   train: batch 61/898  loss=1.9078  0.17s/batch  ETA=2.3m\n",
            "[2026-02-14 10:48:02]   train: batch 128/898  loss=1.9271  0.16s/batch  ETA=2.0m\n"
          ]
        }
      ],
      "source": [
        "# Run training script\n",
        "# Note: Make sure dataset is in train/ and test/ folders\n",
        "!python src/train_model.py"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xSM9nkwNwlst"
      },
      "source": [
        "## 7. Streamlit Demo (Optional)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S8IJl3wewlst"
      },
      "outputs": [],
      "source": [
        "# Run Streamlit app (requires ngrok or localtunnel for Colab)\n",
        "# !pip install streamlit ngrok\n",
        "# !ngrok authtoken YOUR_TOKEN  # Add your ngrok token\n",
        "# !streamlit run src/streamlit_app.py &"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.0"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}